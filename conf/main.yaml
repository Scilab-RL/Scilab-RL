defaults:
  # the name of the algorithm to be used ('td3', 'sac', 'dqn', 'ddpg')
  # here we use hydras config group defaults
  - algorithm: 'sac'
  - override hydra/sweeper: optuna
  - override hydra/sweeper/sampler: tpe
  - override hydra/launcher: custom_joblib # For multiprocessing, allows for n_jobs > 1. Comment this line to use the standard launcher which spawns a single process at a time. The standard launcher is much better for debugging.
  - _self_

# The name of the OpenAI Gym environment that you want to train on.
env: 'FetchReach-v1'

# keyword arguments for the environment
env_kwargs: {}

# The render_args specify how and when to render during training (first sublist) and testing (second sublist).
# 'record' is for video, 'display' for direct visualization, 'none' for not rendering at all.
# The numbers determine the number of epochs after which we render the training/testing.
# Example: [['display',100],['record',10]] means that we display every 100th training and record every 10th testing epoch.
render_args: [['none',100],['record',100]]

# If the seed is 0, it will be set to a pseudo-random value (int(time.time()))
seed: 0

# the path to where logs and policy pickles should go.
base_logdir: 'data'

# The pretrained policy file to start with to avoid learning from scratch again.
# Useful for interrupting and restoring training sessions.
restore_policy: null

# The number of training steps after which to evaluate the policy.
eval_after_n_steps: 5000

# The max. number of training epochs to run. One epoch consists of 'eval_after_n_steps' actions.
n_epochs: 600

# The number of testing rollouts.
n_test_rollouts: 50

# The n last epochs over which to average for determining early stopping condition.
early_stop_last_n: 3

# The early stopping threshold.
early_stop_threshold: 0.9

# The data column on which early stopping is based.
early_stop_data_column: 'eval/success_rate'

# A command line comment that will be integrated in the folder where the results
# are stored. Useful for debugging and addressing temporary changes to the code.
info: ''

# The number of steps after which to save the model. 0 to never save, i.e., to only save the best and last model.
save_model_freq: 0

# The number of object-oriented attributes (utilized only by OO_SAC)
n_attrs: 3

# The number of objects (utilized only by OO_SAC)
n_objects: 3

# WANDB options
# Whether to use Weights and Biases. 1=use, 0=disable
wandb: 0
# wandb project name
project_name: null
# wandb entity
entity: null
# wandb group
group: null
# list of tags
tags: null

hydra:
  run:
    dir: ${base_logdir}/${git_label:}/${env}/${now:%H-%M-%S}
  sweep:
    dir: ${base_logdir}/${git_label:}/${env}/${now:%H-%M-%S}
    subdir: ${hydra.job.num}
